{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d4efb44e",
      "metadata": {
        "id": "d4efb44e"
      },
      "source": [
        "# NLP con Long-Short Term Memory (LSTM)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ohtar10/icesi-nlp/blob/main/Sesion2/2-nlp-with-lstm.ipynb)\n",
        "\n",
        "En este notebook implementaremos un clasificador de noticias en espa침ol utilizando la arquitectura de red LSTM. La idea es tener un punto de referencia para comparar cuando observemos la parte de transformers, por lo que utilizaremos el mismo dataset y tarea de ejemplo. Utilizar칠mos las utilidades de tokenizaci칩n de huggingface transformers para ayudarnos con esta tarea.\n",
        "\n",
        "#### Referencias\n",
        "- Dataset: https://huggingface.co/datasets/MarcOrfilaCarreras/spanish-news\n",
        "- [Long Short-Term Memory](https://www.researchgate.net/publication/13853244_Long_Short-Term_Memory#fullTextFileContent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "936855e4",
      "metadata": {
        "id": "936855e4"
      },
      "outputs": [],
      "source": [
        "import pkg_resources\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "installed_packages = [package.key for package in pkg_resources.working_set]\n",
        "IN_COLAB = 'google-colab' in installed_packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "2013edaf",
      "metadata": {
        "id": "2013edaf",
        "outputId": "f8d7d901-5e19-4ae5-acfd-db7dddafbbab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [Connected to cloud.r-pr\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Waiting for headers] [Connected to r2u.stat.illinois.edu (192.17.190.167)] \r                                                                               \rHit:3 https://cli.github.com/packages stable InRelease\n",
            "\r0% [Waiting for headers] [Connected to r2u.stat.illinois.edu (192.17.190.167)] \r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 128 kB in 3s (38.1 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'python3-distutils' instead of 'python3.10-distutils'\n",
            "Note, selecting 'python3-lib2to3' instead of 'python3.10-lib2to3'\n",
            "python3-distutils is already the newest version (3.10.8-1~22.04).\n",
            "python3-lib2to3 is already the newest version (3.10.8-1~22.04).\n",
            "python3.10 is already the newest version (3.10.12-1~22.04.10).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "update-alternatives: warning: forcing reinstallation of alternative /usr/bin/python3.11 because link group python is broken\n",
            "update-alternatives: warning: not replacing /usr/local/bin/python with a link\n",
            "update-alternatives: warning: forcing reinstallation of alternative /usr/bin/python3.11 because link group python is broken\n",
            "update-alternatives: warning: not replacing /usr/local/bin/python with a link\n",
            "Requirement already satisfied: lightning in /usr/local/lib/python3.11/dist-packages (2.5.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Requirement already satisfied: PyYAML<8.0,>5.4 in /usr/local/lib/python3.11/dist-packages (from lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2027.0,>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning) (2025.3.0)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (0.15.2)\n",
            "Requirement already satisfied: packaging<27.0,>=20.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (25.0)\n",
            "Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchmetrics<3.0,>0.7.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (1.8.1)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>4.5.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (4.14.1)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (from lightning) (2.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.34.4)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning) (3.12.15)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (75.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<4.0,>=2.1.0->lightning) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "#!test '{IN_COLAB}' = 'True' && wget  https://github.com/Ohtar10/icesi-nlp/raw/refs/heads/main/requirements.txt && pip install -r requirements.txt\n",
        "!test '{IN_COLAB}' = 'True' && sudo apt-get update -y\n",
        "!test '{IN_COLAB}' = 'True' && sudo apt-get install python3.10 python3.10-distutils python3.10-lib2to3 -y\n",
        "!test '{IN_COLAB}' = 'True' && sudo update-alternatives --install /usr/local/bin/python python /usr/bin/python3.11 2\n",
        "!test '{IN_COLAB}' = 'True' && sudo update-alternatives --install /usr/local/bin/python python /usr/bin/python3.10 1\n",
        "!test '{IN_COLAB}' = 'True' && pip install lightning datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6df40a98",
      "metadata": {
        "id": "6df40a98"
      },
      "source": [
        "### Cargando el dataset\n",
        "Este es un dataset peque침o de articulos de noticias en idioma espa침ol con sus respectivas categor칤as. El dataset est치 disponible en el HuggingFace Hub y puede ser f치cilmente descargado con la librer칤a."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "02b91601",
      "metadata": {
        "id": "02b91601",
        "outputId": "95d05a40-5275-43ed-c959-c7a429c63255",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['id', 'timestamp', 'pais', 'ciudad', 'canal', 'plataforma', 'medio_contacto', 'comentario', 'categoria', 'severidad', 'sentimiento'],\n",
            "    num_rows: 2000\n",
            "})\n",
            "{'id': '3c0c82e9-c97d-421a-adda-b0e246fdb795', 'timestamp': Timestamp('2024-08-17 14:06:08'), 'pais': 'CL', 'ciudad': 'Lima', 'canal': 'telefono', 'plataforma': 'mobile_web', 'medio_contacto': 'redes', 'comentario': 'En la web/app el cup칩n no funcion칩 al comprar un libro. Intent칠 varias veces y nada.', 'categoria': 'ecommerce', 'severidad': 'media', 'sentimiento': -0.5}\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "from datasets import load_dataset\n",
        "train_url = \"https://raw.githubusercontent.com/mauriciogupi/nlp-master/main/Sesion2/comentarios_train.json\"\n",
        "\n",
        "dataset = load_dataset(\"json\", data_files=train_url, split=\"train\")\n",
        "print(dataset)\n",
        "print(dataset[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9a53ebd",
      "metadata": {
        "id": "f9a53ebd"
      },
      "source": [
        "Observemos uno de sus registros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "14abea7d",
      "metadata": {
        "id": "14abea7d",
        "outputId": "01e86bec-bfce-453e-d010-fa1921939e07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '4ecd2f26-8498-460e-8a6d-32a2c281e205',\n",
              " 'timestamp': Timestamp('2024-08-17 14:43:08'),\n",
              " 'pais': 'ES',\n",
              " 'ciudad': 'Buenos Aires',\n",
              " 'canal': 'whatsapp',\n",
              " 'plataforma': 'desktop',\n",
              " 'medio_contacto': 'telefono',\n",
              " 'comentario': 'El libro mostraba un precio y cobr칩 otro; el descuento era de 20% seg칰n la p치gina.',\n",
              " 'categoria': 'precios',\n",
              " 'severidad': 'media',\n",
              " 'sentimiento': -0.7000000000000001}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "dataset[1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.map(lambda x: {\"timestamp\": str(x[\"timestamp\"])})"
      ],
      "metadata": {
        "id": "Npwnr-SbAEWP",
        "outputId": "6cefa9ab-842f-4db1-d443-5edcfb43814d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e667ffdde87c44e2b47e9122bd72ebba",
            "a144b0f65a6d48449b4b8dfca55d48ae",
            "d14fadcf268c44cc979bfd3b81ccb4dd",
            "0ea48a41f0c64ddb8713ec95c7fd9afe",
            "5ed5416f52c64c2ba004117116afbb94",
            "7f391260a25940f7bd12504517d095f6",
            "66b4f091239349bfacf1e28a39234486",
            "4091367ab02544acb7b79a59e6215087",
            "6bb0996639f4407d87bcf3d5769a3726",
            "67953ebe4e434630a3668706284889ae",
            "90d9c7c2328d48af8ee00a5d43da2ea0"
          ]
        }
      },
      "id": "Npwnr-SbAEWP",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e667ffdde87c44e2b47e9122bd72ebba"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a42e2676",
      "metadata": {
        "id": "a42e2676"
      },
      "source": [
        "Para los efectos de esta tarea, nos servir치n el texto y la categor칤a naturalmente.\n",
        "\n",
        "A manera general, observemos que tan largos o cortos tienden a ser los textos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "c6642761",
      "metadata": {
        "id": "c6642761",
        "outputId": "91f46aeb-0bdd-4dcc-af37-d8251bc9429f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto m치s corto: 50\n",
            "Texto m치s largo: 104\n",
            "Longitud promedio: 83.0965\n"
          ]
        }
      ],
      "source": [
        "text_lengths = [len(row['comentario']) for row in dataset]\n",
        "print(f\"Texto m치s corto: {min(text_lengths)}\")\n",
        "print(f\"Texto m치s largo: {max(text_lengths)}\")\n",
        "print(f\"Longitud promedio: {sum(text_lengths) / len(text_lengths)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19905224",
      "metadata": {
        "id": "19905224"
      },
      "source": [
        "Estos valores son la cantidad de *caract칠res* que tiene las secuencias. Una decisi칩n ingenua pero 칰til en este momento podr칤a ser ajustar la longitud de las secuencias que vamos a usar para el entrenamiento a unos 2000 tokens. Esto podr칤a ser suficiente para capturar una porci칩n significativa de los textos.\n",
        "\n",
        "## Definiendo el Tokenizer\n",
        "\n",
        "Ahora, vamos a definir el tokenizer para nuestra tarea. Para mantener las cosas simples, vamos a mantener un conteo de palabras y vamos a hacer un corte hasta los primeros 50mil tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "18d840a7",
      "metadata": {
        "id": "18d840a7"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def simple_tokenizer(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z치칠칤칩칰칲침]+\", \" \", text)\n",
        "    return text.strip().split()\n",
        "\n",
        "# Construimos el vocabulario a partir de conjunto de datos.\n",
        "token_counts = Counter()\n",
        "for text in dataset[\"comentario\"]:\n",
        "    token_counts.update(simple_tokenizer(text))\n",
        "\n",
        "# 50k-2 porque necesitamos reservar espacio para los dos tokens especiales\n",
        "top_n_tokens = list(token_counts.keys())[:50000-2]\n",
        "vocab = {\"[PAD]\": 0, \"[UNK]\": 1}\n",
        "for token in top_n_tokens:\n",
        "    vocab[token] = len(vocab)\n",
        "\n",
        "def tokenize_text(text, max_length=50):\n",
        "    tokens = simple_tokenizer(text)\n",
        "    ids = [vocab.get(tok, vocab[\"[UNK]\"]) for tok in tokens[:max_length]]\n",
        "    ids += [vocab[\"[PAD]\"]] * (max_length - len(ids))\n",
        "    return ids"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e7ce90e",
      "metadata": {
        "id": "9e7ce90e"
      },
      "source": [
        "Exploremos ahora el tokenizador obtenido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "9f037f43",
      "metadata": {
        "id": "9f037f43",
        "outputId": "ac4d0ce3-664d-4c4b-b9a3-22554be9562d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulario: 313 tokens\n",
            "Primeros 15 tokens:\n",
            "['en', 'la', 'web', 'app', 'el', 'cup칩n', 'no', 'funcion칩', 'al', 'comprar', 'un', 'libro', 'intent칠', 'varias', 'veces']\n",
            "15 tokens de en medio:\n",
            "[]\n",
            "칔ltimos 15 tokens:\n",
            "['tardna', 'zapatlilas', 'serivcio', 'smartwatc', 'hmostraba', 'intent칠v', 'arias', 'naad', 'zapaitllas', 'mojad', 'acon', 'lbiro', 'pap', 'precios', 'ubi칩']\n"
          ]
        }
      ],
      "source": [
        "print(f\"Vocabulario: {len(vocab)} tokens\")\n",
        "print(\"Primeros 15 tokens:\")\n",
        "print(f\"{top_n_tokens[:15]}\")\n",
        "print(\"15 tokens de en medio:\")\n",
        "print(f\"{top_n_tokens[1000:1015]}\")\n",
        "print(\"칔ltimos 15 tokens:\")\n",
        "print(f\"{top_n_tokens[-15:]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fa0668c",
      "metadata": {
        "id": "4fa0668c"
      },
      "source": [
        "Esta forma de exploraci칩n es para darnos una idea de las palabras m치s utilizadas en el corpus y nos dar치 un indicio de si la tokenizaci칩n es adecuada o no. Vemos que tenemos algunos stop words, como art칤culos (el, la) y conectores (del, que). Para una tarea de clasificaci칩n de texto podr칤amos prescindir de estos pero para facilitar las cosas y ya que los dem치s tokens lucen bien, podemos preservarlos.\n",
        "\n",
        "Ahora veamos como convierte el tokenizador una oraci칩n muy sencilla:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "e4e68c73",
      "metadata": {
        "id": "e4e68c73",
        "outputId": "d8879e6a-347f-430d-8f27-32b57459f14a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "tokenized = tokenize_text(\"hola mundo\", max_length=8)\n",
        "tokenized"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "008e6557",
      "metadata": {
        "id": "008e6557"
      },
      "source": [
        "Lo que obtenemos de vuelta son los ids de cada token seg칰n el vocabulario. Ahora algo importante que notamos aqu칤 es el *padding*, durante el entrenamiento, queremos que las secuencias sean de tama침o fijo, para asi operar comodamente con matrices. Pero ya vimos que no todos los textos tienen la misma longitud. Entonces que hacer? para los que son m치s largos que una longitud dada simplemente cortamos, pero para los que son m치s cortos, debemos *rellenar* lo faltante con un *token especial de relleno o padding*. Y es justo lo que definimos all칤, cuando la cadena es inferior a 8 **tokens**, entonces debemos hacer padding hasta que se cumplan los 8.\n",
        "\n",
        "Si queremos saber a que token exactamente hacen referencia estos ids, simplemente revisamos el vocabulario que hemos construido:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "d5049aaf",
      "metadata": {
        "id": "d5049aaf",
        "outputId": "309a75ec-354a-4ba7-e800-916935831ef5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[UNK]', '[UNK]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "id_2_token = {v: k for k, v in vocab.items()}\n",
        "[id_2_token[token] for token in tokenized]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c18e433",
      "metadata": {
        "id": "9c18e433"
      },
      "source": [
        "Claramente vemos los 3 tokens como cadenas independientes (el padding se considera un token independiente).\n",
        "\n",
        "### Definiendo el dataset de pytorch\n",
        "Ahora podemos proceder a definir el dataset. Esto deber칤a ser muy sencillo dado que nuestro dataset es peque침o y ya tenemos el tokenizador listo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "ca70e65a",
      "metadata": {
        "id": "ca70e65a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from typing import Tuple, Dict\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SpanishNewsDataset(Dataset):\n",
        "\n",
        "    def __init__(self, tokenizer, dataset, seq_length: int = 512):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.dataset = dataset\n",
        "        self.seq_length = seq_length\n",
        "        # Definimos estos dos mapas para facilitarnos la tarea\n",
        "        # de traducir de nombres de categor칤a a ids de categor칤a.\n",
        "        self.id_2_class_map = dict(enumerate(np.unique(dataset[:]['categoria'])))\n",
        "        self.class_2_id_map = {v: k for k, v in self.id_2_class_map.items()}\n",
        "        self.num_classes = len(self.id_2_class_map)\n",
        "\n",
        "    def __getitem__(self, index) -> Dict[str, torch.Tensor]:\n",
        "        text, y = self.dataset[index]['comentario'], self.dataset[index]['categoria']\n",
        "        y = self.class_2_id_map[y]\n",
        "        data = {'id': torch.tensor(self.tokenizer(text, max_length=self.seq_length))}\n",
        "        data['y'] = torch.tensor(y)\n",
        "        return data\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56de3493",
      "metadata": {
        "id": "56de3493"
      },
      "source": [
        "Ahora instanciaremos el dataset entero. Para este experimento, definiremos un tama침o m치ximo de secuencia de 2048 **tokens**. Que seg칰n nuestra intuici칩n arriba, deber칤a ser suficiente para la tarea."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "15200ea5",
      "metadata": {
        "id": "15200ea5"
      },
      "outputs": [],
      "source": [
        "max_len = 512\n",
        "spanish_news_dataset = SpanishNewsDataset(tokenize_text, dataset, seq_length=max_len)\n",
        "assert len(spanish_news_dataset) == len(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "611d4b0b",
      "metadata": {
        "id": "611d4b0b"
      },
      "source": [
        "Y luego, procedemos a hacer el train-val-test split y crear los dataloaders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "6d7e9e1c",
      "metadata": {
        "id": "6d7e9e1c"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 4 if not IN_COLAB else 12\n",
        "train_dataset, val_dataset, test_dataset = random_split(spanish_news_dataset, lengths=[0.8, 0.1, 0.1])\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ac44796",
      "metadata": {
        "id": "5ac44796"
      },
      "source": [
        "## Definici칩n del modelo LSTM\n",
        "\n",
        "Ahora vamos a configurar un m칩dulo pytorch simple para este problema. Vamos ha utilizar los embeddings, que vendr칤an siendo los vectores de palabra. Pytorch nos ofrece una capa con la que directamente podemos entrenarlos a partir de los token ids obtenidos. El resto consistir치 en invocar una capa LSTM seguida de una capa densa para la clasificaci칩n.\n",
        "\n",
        "Recordemos que las redes recurrentes como las LSTM por dise침o enlazan todas las dimensiones del vector de entrada, formando as칤 la secuencia, la estructura natural que necesitamos representar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "d38eb14b",
      "metadata": {
        "id": "d38eb14b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LSTMBlock(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes, num_layers=2, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, (hidden, _) = self.lstm(embedded)\n",
        "        return hidden[-1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32f68240",
      "metadata": {
        "id": "32f68240"
      },
      "source": [
        "### Definici칩n del clasificador\n",
        "\n",
        "Finalmente, definimos el modelo en si. Este modelo constar치 de 3 capas:\n",
        "\n",
        "- La tokenizaci칩n, tal como la definimos anteriormente.\n",
        "- El bloque LSTM, que acabamos de decinir.\n",
        "- Una capa densa adicional que servir치 como clasificador de aquello que nos entregue la capa del transformer.\n",
        "\n",
        "Como este es un LightningModule, aqu칤 definiremos el resto de funciones utilitarias para el entrenamiento de la tarea."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "1d724f85",
      "metadata": {
        "id": "1d724f85",
        "outputId": "063c38f4-f295-457b-92de-31ce371d52be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720,
          "referenced_widgets": [
            "218ac8153f954058b81739134de6465f",
            "14cde806cf2c4a22b8b21b409cf7482c",
            "3261efeb2e644db9b7ce94ff7a6717c1",
            "f8a4cef5dcbc487b92d4ec13db4ab668",
            "97091d736ccd41879c3e0d4ebb035764",
            "6365c9eef1af46a9a051b509be6059ed",
            "0bf42c884453444ebc5e6d38f94ec3c1",
            "9adeac374d914d678332ffc714d6db49",
            "39789921577a4247803357c094dc6b40",
            "be75b53f12654086a52f34e99d40224b",
            "fe84b402965540d0936ab3d9842de636"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Using bfloat16 Automatic Mixed Precision (AMP)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:游눠 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name       | Type               | Params | Mode \n",
            "----------------------------------------------------------\n",
            "0 | lstm       | LSTMBlock          | 410 K  | train\n",
            "1 | classifier | Sequential         | 198 K  | train\n",
            "2 | train_acc  | MulticlassAccuracy | 0      | train\n",
            "3 | val_acc    | MulticlassAccuracy | 0      | train\n",
            "4 | test_acc   | MulticlassAccuracy | 0      | train\n",
            "----------------------------------------------------------\n",
            "608 K     Trainable params\n",
            "0         Non-trainable params\n",
            "608 K     Total params\n",
            "2.434     Total estimated model params size (MB)\n",
            "16        Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "218ac8153f954058b81739134de6465f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "could not create a primitive descriptor for an LSTM forward propagation primitive",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2077137122.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_logger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"16-mixed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    562\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         )\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;31m# RUN THE TRAINER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0misolate_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m             \u001b[0;31m# run eval step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m             \u001b[0mval_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_callback_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"on_sanity_check_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/utilities.py\u001b[0m in \u001b[0;36m_decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mcontext_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcontext_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mloop_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_decorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/evaluation_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_progress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_last_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0;31m# run step hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;31m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/evaluation_loop.py\u001b[0m in \u001b[0;36m_evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         )\n\u001b[0;32m--> 437\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_strategy_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstep_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_progress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincrement_processed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Strategy]{trainer.strategy.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_redirection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSTEP_OUTPUT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2077137122.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2077137122.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1529012800.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m             result = _VF.lstm(\n\u001b[0m\u001b[1;32m   1125\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m                 \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: could not create a primitive descriptor for an LSTM forward propagation primitive"
          ]
        }
      ],
      "source": [
        "from pytorch_lightning import LightningModule, Trainer\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "class SpanishNewsClassifierWithLSTM(LightningModule):\n",
        "\n",
        "    def __init__(self, vocab_size: int, num_classes: int, emb_dim: int, hidden_dim: int = 128):\n",
        "        super(SpanishNewsClassifierWithLSTM, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.lstm = LSTMBlock(vocab_size, emb_dim, hidden_dim, num_classes)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(hidden_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(256, num_classes),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "        self.train_acc = Accuracy(task='multiclass', num_classes=num_classes)\n",
        "        self.val_acc = Accuracy(task='multiclass', num_classes=num_classes)\n",
        "        self.test_acc = Accuracy(task='multiclass', num_classes=num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embeddings = self.lstm(x)\n",
        "        return self.classifier(embeddings)\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch['input_ids'], batch['y']\n",
        "        # print(f\"\\nbatch-idx: {batch_idx}\")\n",
        "        # print(f\"shape of x: {x.shape}\")\n",
        "        # print(torch.max(x, dim=0))\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "        self.train_acc(y_hat, y)\n",
        "        self.log('train-loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
        "        self.log('train-acc', self.train_acc, prog_bar=True, on_step=False, on_epoch=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        x, y = batch['id'], batch['y']\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "        self.val_acc(y_hat, y)\n",
        "        self.log('val-loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
        "        self.log('val-acc', self.val_acc, prog_bar=True, on_step=False, on_epoch=True)\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch):\n",
        "        x, y = batch['id'], batch['y']\n",
        "        y_hat = self(x)\n",
        "        self.test_acc(y_hat, y)\n",
        "        self.log('test-acc', self.test_acc, prog_bar=True, on_step=False, on_epoch=True)\n",
        "\n",
        "\n",
        "    def predict_step(self, batch):\n",
        "        x = batch['id']\n",
        "        return self(x)\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer =  torch.optim.AdamW(self.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "        return optimizer\n",
        "\n",
        "\n",
        "model = SpanishNewsClassifierWithLSTM(vocab_size=len(vocab) + 1, num_classes=spanish_news_dataset.num_classes, emb_dim=256)\n",
        "\n",
        "tb_logger = TensorBoardLogger('tb_logs', name='LSTMClassifier')\n",
        "callbacks=[EarlyStopping(monitor='train-loss', patience=3, mode='min')]\n",
        "trainer = Trainer(max_epochs=10, devices=1, logger=tb_logger, callbacks=callbacks, precision=\"16-mixed\")\n",
        "\n",
        "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7312d7c",
      "metadata": {
        "id": "b7312d7c"
      },
      "source": [
        "Observemos el proceso de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65f9b20e",
      "metadata": {
        "id": "65f9b20e"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e6dc01e",
      "metadata": {
        "id": "8e6dc01e",
        "outputId": "f4086caa-6a49-4780-a301-0228069c918d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-42fd403edfc8a0e6\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-42fd403edfc8a0e6\");\n",
              "          const url = new URL(\"/\", window.location);\n",
              "          const port = 6006;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%tensorboard --logdir tb_logs/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5dd09d6",
      "metadata": {
        "id": "f5dd09d6"
      },
      "source": [
        "Y como es de esperarse, realizaremos la validaci칩n contra el conjunto de prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5d52f43",
      "metadata": {
        "id": "a5d52f43",
        "outputId": "1098e51d-c1ed-4533-9e22-35d467cd476e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing DataLoader 0: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 255/255 [00:01<00:00, 237.12it/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較늎n",
              "較<span style=\"font-weight: bold\">        Test metric        </span>較<span style=\"font-weight: bold\">       DataLoader 0        </span>較\n",
              "較뫡대較較較較較較較較較較較較較較較較較較較較較較較較較較轎較較較較較較較較較較較較較較較較較較較較較較較較較較較較뼆n",
              "較<span style=\"color: #008080; text-decoration-color: #008080\">         test-acc          </span>較<span style=\"color: #800080; text-decoration-color: #800080\">    0.9029411673545837     </span>較\n",
              "較덕較較較較較較較較較較較較較較較較較較較較較較較較較較較억較較較較較較較較較較較較較較較較較較較較較較較較較較較\n",
              "</pre>\n"
            ],
            "text/plain": [
              "較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較늎n",
              "較\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m較\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m較\n",
              "較뫡대較較較較較較較較較較較較較較較較較較較較較較較較較較轎較較較較較較較較較較較較較較較較較較較較較較較較較較較較뼆n",
              "較\u001b[36m \u001b[0m\u001b[36m        test-acc         \u001b[0m\u001b[36m \u001b[0m較\u001b[35m \u001b[0m\u001b[35m   0.9029411673545837    \u001b[0m\u001b[35m \u001b[0m較\n",
              "較덕較較較較較較較較較較較較較較較較較較較較較較較較較較較억較較較較較較較較較較較較較較較較較較較較較較較較較較較\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "[{'test-acc': 0.9029411673545837}]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.eval()\n",
        "trainer.test(model, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad06d232",
      "metadata": {
        "id": "ad06d232"
      },
      "source": [
        "### Haciendo predicciones\n",
        "\n",
        "Finalmente, vamos a hacer uso del modelo y ver que tan bueno es para la clasificaci칩n de noticias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff1c989e",
      "metadata": {
        "id": "ff1c989e",
        "outputId": "dff49068-8f68-4d54-be20-d41aa1db2c9b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting DataLoader 0: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 255/255 [00:01<00:00, 219.44it/s]\n"
          ]
        }
      ],
      "source": [
        "predictions = trainer.predict(model, test_loader)\n",
        "predictions = torch.cat(predictions, dim=0)\n",
        "predictions = torch.argmax(predictions, dim=-1)\n",
        "predictions = [spanish_news_dataset.id_2_class_map[pred] for pred in predictions.numpy()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bdacb5c",
      "metadata": {
        "id": "8bdacb5c",
        "outputId": "848bdc2b-cf67-44f1-d177-0d1bec5adc2b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>tokens</th>\n",
              "      <th>tokens_string</th>\n",
              "      <th>categor칤a</th>\n",
              "      <th>predicci칩n</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6734</th>\n",
              "      <td>El Gobierno tiene un plan alternativo para ase...</td>\n",
              "      <td>[5, 3270, 1058, 102, 1737, 4007, 240, 834, 10,...</td>\n",
              "      <td>el gobierno tiene un plan alternativo para ase...</td>\n",
              "      <td>politics</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1905</th>\n",
              "      <td>Prevalencia de hipotiroidismo subcl칤nico y su ...</td>\n",
              "      <td>[34012, 12, 1, 1, 36, 46, 703, 58, 1, 36, 1652...</td>\n",
              "      <td>prevalencia de [UNK] [UNK] y su relaci칩n con [...</td>\n",
              "      <td>medicine</td>\n",
              "      <td>medicine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3049</th>\n",
              "      <td>El Sol, la fuente inagotable de energ칤a que da...</td>\n",
              "      <td>[5, 14608, 14, 2248, 10396, 12, 2641, 10, 246,...</td>\n",
              "      <td>el sol la fuente inagotable de energ칤a que da ...</td>\n",
              "      <td>astronomy</td>\n",
              "      <td>astronomy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1772</th>\n",
              "      <td>Mondor en la mama. A prop칩sito de un casoLa en...</td>\n",
              "      <td>[1, 54, 14, 1, 40, 554, 12, 102, 1, 1652, 12, ...</td>\n",
              "      <td>[UNK] en la [UNK] a prop칩sito de un [UNK] enfe...</td>\n",
              "      <td>medicine</td>\n",
              "      <td>medicine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6980</th>\n",
              "      <td>Navantia acaba de firmar con la Marina de Noru...</td>\n",
              "      <td>[1, 11, 12, 23970, 58, 14, 27045, 12, 27768, 1...</td>\n",
              "      <td>[UNK] acaba de firmar con la marina de noruega...</td>\n",
              "      <td>military</td>\n",
              "      <td>military</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1589</th>\n",
              "      <td>Tienen una funci칩n parecida a los relojes o la...</td>\n",
              "      <td>[440, 19, 2427, 14721, 40, 34, 14066, 96, 77, ...</td>\n",
              "      <td>tienen una funci칩n parecida a los relojes o la...</td>\n",
              "      <td>tech</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>240</th>\n",
              "      <td>En 칰ltima instancia, cuando se apagan las luce...</td>\n",
              "      <td>[54, 1177, 5104, 206, 17, 16158, 77, 3867, 12,...</td>\n",
              "      <td>en 칰ltima instancia cuando se apagan las luces...</td>\n",
              "      <td>play</td>\n",
              "      <td>play</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7356</th>\n",
              "      <td>La compa침칤a francesa Escape International ha p...</td>\n",
              "      <td>[14, 1151, 2772, 7008, 29665, 260, 1048, 54, 1...</td>\n",
              "      <td>la compa침칤a francesa escape international ha p...</td>\n",
              "      <td>military</td>\n",
              "      <td>military</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6763</th>\n",
              "      <td>El Gobierno busca que Bruselas apruebe un impu...</td>\n",
              "      <td>[5, 3270, 232, 10, 14032, 36279, 102, 15003, 2...</td>\n",
              "      <td>el gobierno busca que bruselas apruebe un impu...</td>\n",
              "      <td>politics</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3341</th>\n",
              "      <td>comentarios 44Cybertron, el planeta de losTra...</td>\n",
              "      <td>[7493, 1, 5, 3124, 12, 34, 8114, 5, 29619, 12,...</td>\n",
              "      <td>comentarios [UNK] el planeta de los transforme...</td>\n",
              "      <td>astronomy</td>\n",
              "      <td>astronomy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7826</th>\n",
              "      <td>La palabra bienquerencia es poco usada, pero e...</td>\n",
              "      <td>[14, 203, 1, 4, 610, 32326, 403, 198, 11659, 2...</td>\n",
              "      <td>la palabra [UNK] es poco usada pero existe ind...</td>\n",
              "      <td>religion</td>\n",
              "      <td>religion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8578</th>\n",
              "      <td>Segunda victoria en el WRC para el finland칠s E...</td>\n",
              "      <td>[1090, 3982, 54, 5, 1, 240, 5, 19053, 1, 1, 10...</td>\n",
              "      <td>segunda victoria en el [UNK] para el finland칠s...</td>\n",
              "      <td>motor</td>\n",
              "      <td>motor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3456</th>\n",
              "      <td>No hay un equipo m치s desgraciado que el Almer칤...</td>\n",
              "      <td>[196, 124, 102, 4877, 130, 20027, 10, 5, 23674...</td>\n",
              "      <td>no hay un equipo m치s desgraciado que el almer칤...</td>\n",
              "      <td>sport</td>\n",
              "      <td>sport</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5659</th>\n",
              "      <td>M치s all치 de las c치psulas de caf칠 hay un mundo ...</td>\n",
              "      <td>[130, 219, 12, 77, 32819, 12, 10027, 124, 102,...</td>\n",
              "      <td>m치s all치 de las c치psulas de caf칠 hay un mundo ...</td>\n",
              "      <td>alimentation</td>\n",
              "      <td>alimentation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2184</th>\n",
              "      <td>Evolucion de la vida sexual de la mujer. Fisio...</td>\n",
              "      <td>[1, 12, 14, 195, 7773, 12, 14, 749, 1, 12, 14,...</td>\n",
              "      <td>[UNK] de la vida sexual de la mujer [UNK] de l...</td>\n",
              "      <td>medicine</td>\n",
              "      <td>medicine</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto  \\\n",
              "6734  El Gobierno tiene un plan alternativo para ase...   \n",
              "1905  Prevalencia de hipotiroidismo subcl칤nico y su ...   \n",
              "3049  El Sol, la fuente inagotable de energ칤a que da...   \n",
              "1772  Mondor en la mama. A prop칩sito de un casoLa en...   \n",
              "6980  Navantia acaba de firmar con la Marina de Noru...   \n",
              "1589  Tienen una funci칩n parecida a los relojes o la...   \n",
              "240   En 칰ltima instancia, cuando se apagan las luce...   \n",
              "7356  La compa침칤a francesa Escape International ha p...   \n",
              "6763  El Gobierno busca que Bruselas apruebe un impu...   \n",
              "3341  comentarios 44Cybertron, el planeta de losTra...   \n",
              "7826  La palabra bienquerencia es poco usada, pero e...   \n",
              "8578  Segunda victoria en el WRC para el finland칠s E...   \n",
              "3456  No hay un equipo m치s desgraciado que el Almer칤...   \n",
              "5659  M치s all치 de las c치psulas de caf칠 hay un mundo ...   \n",
              "2184  Evolucion de la vida sexual de la mujer. Fisio...   \n",
              "\n",
              "                                                 tokens  \\\n",
              "6734  [5, 3270, 1058, 102, 1737, 4007, 240, 834, 10,...   \n",
              "1905  [34012, 12, 1, 1, 36, 46, 703, 58, 1, 36, 1652...   \n",
              "3049  [5, 14608, 14, 2248, 10396, 12, 2641, 10, 246,...   \n",
              "1772  [1, 54, 14, 1, 40, 554, 12, 102, 1, 1652, 12, ...   \n",
              "6980  [1, 11, 12, 23970, 58, 14, 27045, 12, 27768, 1...   \n",
              "1589  [440, 19, 2427, 14721, 40, 34, 14066, 96, 77, ...   \n",
              "240   [54, 1177, 5104, 206, 17, 16158, 77, 3867, 12,...   \n",
              "7356  [14, 1151, 2772, 7008, 29665, 260, 1048, 54, 1...   \n",
              "6763  [5, 3270, 232, 10, 14032, 36279, 102, 15003, 2...   \n",
              "3341  [7493, 1, 5, 3124, 12, 34, 8114, 5, 29619, 12,...   \n",
              "7826  [14, 203, 1, 4, 610, 32326, 403, 198, 11659, 2...   \n",
              "8578  [1090, 3982, 54, 5, 1, 240, 5, 19053, 1, 1, 10...   \n",
              "3456  [196, 124, 102, 4877, 130, 20027, 10, 5, 23674...   \n",
              "5659  [130, 219, 12, 77, 32819, 12, 10027, 124, 102,...   \n",
              "2184  [1, 12, 14, 195, 7773, 12, 14, 749, 1, 12, 14,...   \n",
              "\n",
              "                                          tokens_string     categor칤a  \\\n",
              "6734  el gobierno tiene un plan alternativo para ase...      politics   \n",
              "1905  prevalencia de [UNK] [UNK] y su relaci칩n con [...      medicine   \n",
              "3049  el sol la fuente inagotable de energ칤a que da ...     astronomy   \n",
              "1772  [UNK] en la [UNK] a prop칩sito de un [UNK] enfe...      medicine   \n",
              "6980  [UNK] acaba de firmar con la marina de noruega...      military   \n",
              "1589  tienen una funci칩n parecida a los relojes o la...          tech   \n",
              "240   en 칰ltima instancia cuando se apagan las luces...          play   \n",
              "7356  la compa침칤a francesa escape international ha p...      military   \n",
              "6763  el gobierno busca que bruselas apruebe un impu...      politics   \n",
              "3341  comentarios [UNK] el planeta de los transforme...     astronomy   \n",
              "7826  la palabra [UNK] es poco usada pero existe ind...      religion   \n",
              "8578  segunda victoria en el [UNK] para el finland칠s...         motor   \n",
              "3456  no hay un equipo m치s desgraciado que el almer칤...         sport   \n",
              "5659  m치s all치 de las c치psulas de caf칠 hay un mundo ...  alimentation   \n",
              "2184  [UNK] de la vida sexual de la mujer [UNK] de l...      medicine   \n",
              "\n",
              "        predicci칩n  \n",
              "6734      politics  \n",
              "1905      medicine  \n",
              "3049     astronomy  \n",
              "1772      medicine  \n",
              "6980      military  \n",
              "1589          tech  \n",
              "240           play  \n",
              "7356      military  \n",
              "6763      politics  \n",
              "3341     astronomy  \n",
              "7826      religion  \n",
              "8578         motor  \n",
              "3456         sport  \n",
              "5659  alimentation  \n",
              "2184      medicine  "
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "test_indices = test_dataset.indices\n",
        "df = pd.DataFrame(data={\n",
        "    \"texto\": dataset[test_indices]['text'],\n",
        "    \"tokens\": [tokenize_text(v) for v in dataset[test_indices]['text']],\n",
        "    \"categor칤a\": dataset[test_indices]['category'],\n",
        "    'predicci칩n': predictions\n",
        "}, index=test_indices)\n",
        "\n",
        "df['tokens_string'] = df.tokens.apply(lambda t: ' '.join([id_2_token[i] for i in t]))\n",
        "df = df[[\"texto\", \"tokens\", \"tokens_string\", \"categor칤a\", \"predicci칩n\"]]\n",
        "df.style.set_table_styles(\n",
        "    [\n",
        "        {'selector': 'td', 'props': [('word-wrap', 'break-word')]}\n",
        "    ]\n",
        ")\n",
        "df.head(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c5085d5",
      "metadata": {
        "id": "9c5085d5",
        "outputId": "15e4bf3a-00e0-4245-f3de-84b86f44b40b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>tokens</th>\n",
              "      <th>tokens_string</th>\n",
              "      <th>categor칤a</th>\n",
              "      <th>predicci칩n</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1120</th>\n",
              "      <td>Pues parece que la polic칤a holandesa se precip...</td>\n",
              "      <td>[2020, 491, 10, 14, 1497, 38011, 17, 38012, 10...</td>\n",
              "      <td>pues parece que la polic칤a holandesa se precip...</td>\n",
              "      <td>tech</td>\n",
              "      <td>play</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7473</th>\n",
              "      <td>El nuevo Consejo de Administraci칩n deFincanti...</td>\n",
              "      <td>[5, 8, 17379, 12, 444, 12, 1, 1, 29649, 45, 14...</td>\n",
              "      <td>el nuevo consejo de administraci칩n de [UNK] [U...</td>\n",
              "      <td>military</td>\n",
              "      <td>economy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2765</th>\n",
              "      <td>Fuente de la imagen, OtherJune Williams creci칩...</td>\n",
              "      <td>[2248, 12, 14, 564, 1, 10953, 5680, 57, 40, 34...</td>\n",
              "      <td>fuente de la imagen [UNK] williams creci칩 junt...</td>\n",
              "      <td>astronomy</td>\n",
              "      <td>religion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4142</th>\n",
              "      <td>El Elche espera a 칍scar Plano. El delantero ma...</td>\n",
              "      <td>[5, 36649, 4040, 40, 2947, 1846, 5, 1, 8710, 3...</td>\n",
              "      <td>el elche espera a 칩scar plano el [UNK] madrile...</td>\n",
              "      <td>sport</td>\n",
              "      <td>economy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>689</th>\n",
              "      <td>Algunos de los monumentos m치s famosos del Rein...</td>\n",
              "      <td>[501, 12, 34, 23928, 130, 1018, 7, 2125, 8269,...</td>\n",
              "      <td>algunos de los monumentos m치s famosos del rein...</td>\n",
              "      <td>play</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5835</th>\n",
              "      <td>Hay anuncios que irremediablemente se quedan a...</td>\n",
              "      <td>[124, 11554, 10, 12505, 17, 1895, 12251, 54, 2...</td>\n",
              "      <td>hay anuncios que irremediablemente se quedan a...</td>\n",
              "      <td>alimentation</td>\n",
              "      <td>astronomy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7368</th>\n",
              "      <td>Navantia junto a otras 5 grandes empresas, Rep...</td>\n",
              "      <td>[1, 57, 40, 2255, 901, 8594, 1, 1, 14784, 3176...</td>\n",
              "      <td>[UNK] junto a otras grandes empresas [UNK] [UN...</td>\n",
              "      <td>military</td>\n",
              "      <td>motor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9001</th>\n",
              "      <td>La versi칩n m치s accesible del Lucid Air llega p...</td>\n",
              "      <td>[14, 2049, 130, 14266, 7, 1, 7550, 333, 45, 31...</td>\n",
              "      <td>la versi칩n m치s accesible del [UNK] air llega p...</td>\n",
              "      <td>motor</td>\n",
              "      <td>economy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7846</th>\n",
              "      <td>Pedro S치nchez ha regalado toda una ley de adoc...</td>\n",
              "      <td>[399, 9554, 260, 19502, 89, 19, 2565, 12, 1, 5...</td>\n",
              "      <td>pedro s치nchez ha regalado toda una ley de [UNK...</td>\n",
              "      <td>religion</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8103</th>\n",
              "      <td>Es algo que est치 sorprendiendo en la red. Mill...</td>\n",
              "      <td>[4, 559, 10, 482, 24341, 54, 14, 1063, 1059, 1...</td>\n",
              "      <td>es algo que est치 sorprendiendo en la red millo...</td>\n",
              "      <td>religion</td>\n",
              "      <td>astronomy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9900</th>\n",
              "      <td>La Edad Media no fue la 칠poca maloliente y suc...</td>\n",
              "      <td>[14, 7466, 4151, 196, 395, 14, 1629, 1, 36, 47...</td>\n",
              "      <td>la edad media no fue la 칠poca [UNK] y sucia qu...</td>\n",
              "      <td>economy</td>\n",
              "      <td>astronomy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>786</th>\n",
              "      <td>La 칰ltima generaci칩n de videoconsolas lanzadas...</td>\n",
              "      <td>[14, 1177, 2224, 12, 30807, 21743, 269, 1481, ...</td>\n",
              "      <td>la 칰ltima generaci칩n de videoconsolas lanzadas...</td>\n",
              "      <td>play</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9576</th>\n",
              "      <td>La necesidad de energ칤a est치 presente en pr치ct...</td>\n",
              "      <td>[14, 2497, 12, 2641, 482, 388, 54, 4057, 201, ...</td>\n",
              "      <td>la necesidad de energ칤a est치 presente en pr치ct...</td>\n",
              "      <td>economy</td>\n",
              "      <td>fashion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2098</th>\n",
              "      <td>쯈u칠 es la farmacolog칤a? Ciencia que estudia l...</td>\n",
              "      <td>[1183, 4, 14, 1, 4182, 10, 38159, 34, 11561, 1...</td>\n",
              "      <td>qu칠 es la [UNK] ciencia que estudia los f치rmac...</td>\n",
              "      <td>medicine</td>\n",
              "      <td>military</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7888</th>\n",
              "      <td>El Ayuntamiento de Palma ha colocado este mart...</td>\n",
              "      <td>[5, 4852, 12, 9239, 260, 15095, 55, 9247, 14, ...</td>\n",
              "      <td>el ayuntamiento de palma ha colocado este mart...</td>\n",
              "      <td>religion</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto  \\\n",
              "1120  Pues parece que la polic칤a holandesa se precip...   \n",
              "7473  El nuevo Consejo de Administraci칩n deFincanti...   \n",
              "2765  Fuente de la imagen, OtherJune Williams creci칩...   \n",
              "4142  El Elche espera a 칍scar Plano. El delantero ma...   \n",
              "689   Algunos de los monumentos m치s famosos del Rein...   \n",
              "5835  Hay anuncios que irremediablemente se quedan a...   \n",
              "7368  Navantia junto a otras 5 grandes empresas, Rep...   \n",
              "9001  La versi칩n m치s accesible del Lucid Air llega p...   \n",
              "7846  Pedro S치nchez ha regalado toda una ley de adoc...   \n",
              "8103  Es algo que est치 sorprendiendo en la red. Mill...   \n",
              "9900  La Edad Media no fue la 칠poca maloliente y suc...   \n",
              "786   La 칰ltima generaci칩n de videoconsolas lanzadas...   \n",
              "9576  La necesidad de energ칤a est치 presente en pr치ct...   \n",
              "2098  쯈u칠 es la farmacolog칤a? Ciencia que estudia l...   \n",
              "7888  El Ayuntamiento de Palma ha colocado este mart...   \n",
              "\n",
              "                                                 tokens  \\\n",
              "1120  [2020, 491, 10, 14, 1497, 38011, 17, 38012, 10...   \n",
              "7473  [5, 8, 17379, 12, 444, 12, 1, 1, 29649, 45, 14...   \n",
              "2765  [2248, 12, 14, 564, 1, 10953, 5680, 57, 40, 34...   \n",
              "4142  [5, 36649, 4040, 40, 2947, 1846, 5, 1, 8710, 3...   \n",
              "689   [501, 12, 34, 23928, 130, 1018, 7, 2125, 8269,...   \n",
              "5835  [124, 11554, 10, 12505, 17, 1895, 12251, 54, 2...   \n",
              "7368  [1, 57, 40, 2255, 901, 8594, 1, 1, 14784, 3176...   \n",
              "9001  [14, 2049, 130, 14266, 7, 1, 7550, 333, 45, 31...   \n",
              "7846  [399, 9554, 260, 19502, 89, 19, 2565, 12, 1, 5...   \n",
              "8103  [4, 559, 10, 482, 24341, 54, 14, 1063, 1059, 1...   \n",
              "9900  [14, 7466, 4151, 196, 395, 14, 1629, 1, 36, 47...   \n",
              "786   [14, 1177, 2224, 12, 30807, 21743, 269, 1481, ...   \n",
              "9576  [14, 2497, 12, 2641, 482, 388, 54, 4057, 201, ...   \n",
              "2098  [1183, 4, 14, 1, 4182, 10, 38159, 34, 11561, 1...   \n",
              "7888  [5, 4852, 12, 9239, 260, 15095, 55, 9247, 14, ...   \n",
              "\n",
              "                                          tokens_string     categor칤a  \\\n",
              "1120  pues parece que la polic칤a holandesa se precip...          tech   \n",
              "7473  el nuevo consejo de administraci칩n de [UNK] [U...      military   \n",
              "2765  fuente de la imagen [UNK] williams creci칩 junt...     astronomy   \n",
              "4142  el elche espera a 칩scar plano el [UNK] madrile...         sport   \n",
              "689   algunos de los monumentos m치s famosos del rein...          play   \n",
              "5835  hay anuncios que irremediablemente se quedan a...  alimentation   \n",
              "7368  [UNK] junto a otras grandes empresas [UNK] [UN...      military   \n",
              "9001  la versi칩n m치s accesible del [UNK] air llega p...         motor   \n",
              "7846  pedro s치nchez ha regalado toda una ley de [UNK...      religion   \n",
              "8103  es algo que est치 sorprendiendo en la red millo...      religion   \n",
              "9900  la edad media no fue la 칠poca [UNK] y sucia qu...       economy   \n",
              "786   la 칰ltima generaci칩n de videoconsolas lanzadas...          play   \n",
              "9576  la necesidad de energ칤a est치 presente en pr치ct...       economy   \n",
              "2098  qu칠 es la [UNK] ciencia que estudia los f치rmac...      medicine   \n",
              "7888  el ayuntamiento de palma ha colocado este mart...      religion   \n",
              "\n",
              "     predicci칩n  \n",
              "1120       play  \n",
              "7473    economy  \n",
              "2765   religion  \n",
              "4142    economy  \n",
              "689        tech  \n",
              "5835  astronomy  \n",
              "7368      motor  \n",
              "9001    economy  \n",
              "7846   politics  \n",
              "8103  astronomy  \n",
              "9900  astronomy  \n",
              "786        tech  \n",
              "9576    fashion  \n",
              "2098   military  \n",
              "7888   politics  "
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "errors = df[df['categor칤a'] != df['predicci칩n']]\n",
        "errors.head(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88103e5e",
      "metadata": {
        "id": "88103e5e"
      },
      "source": [
        "## Conclusiones\n",
        "\n",
        "- En este caso tenemos una tarea de clasificaci칩n de texto de m칰ltiples clases.\n",
        "- Estamos usando un bloque LSTM como featurizer, es decir lo usamos para extraer features de las secuencias de entrada con las cuales har칠mos predicciones luego.\n",
        "- N칩tese que de las capas LSTM, solo nos interesa la 칰ltima, ya que esta recupera todas las operaciones enalazadas anteriores.\n",
        "- Observamos que el modelo toma su tiempo en entrenar, esto es natural debido al dise침o de las LSTM, donde por cada paso de tiempo se debe computar un gradiente, por lo que el computo es mucho mayor."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e73526f",
      "metadata": {
        "id": "4e73526f"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "icesi-nlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e667ffdde87c44e2b47e9122bd72ebba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a144b0f65a6d48449b4b8dfca55d48ae",
              "IPY_MODEL_d14fadcf268c44cc979bfd3b81ccb4dd",
              "IPY_MODEL_0ea48a41f0c64ddb8713ec95c7fd9afe"
            ],
            "layout": "IPY_MODEL_5ed5416f52c64c2ba004117116afbb94"
          }
        },
        "a144b0f65a6d48449b4b8dfca55d48ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f391260a25940f7bd12504517d095f6",
            "placeholder": "",
            "style": "IPY_MODEL_66b4f091239349bfacf1e28a39234486",
            "value": "Map:100%"
          }
        },
        "d14fadcf268c44cc979bfd3b81ccb4dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4091367ab02544acb7b79a59e6215087",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6bb0996639f4407d87bcf3d5769a3726",
            "value": 2000
          }
        },
        "0ea48a41f0c64ddb8713ec95c7fd9afe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67953ebe4e434630a3668706284889ae",
            "placeholder": "",
            "style": "IPY_MODEL_90d9c7c2328d48af8ee00a5d43da2ea0",
            "value": "2000/2000[00:00&lt;00:00,5943.42examples/s]"
          }
        },
        "5ed5416f52c64c2ba004117116afbb94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f391260a25940f7bd12504517d095f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66b4f091239349bfacf1e28a39234486": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4091367ab02544acb7b79a59e6215087": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bb0996639f4407d87bcf3d5769a3726": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67953ebe4e434630a3668706284889ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90d9c7c2328d48af8ee00a5d43da2ea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "218ac8153f954058b81739134de6465f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_14cde806cf2c4a22b8b21b409cf7482c",
              "IPY_MODEL_3261efeb2e644db9b7ce94ff7a6717c1",
              "IPY_MODEL_f8a4cef5dcbc487b92d4ec13db4ab668"
            ],
            "layout": "IPY_MODEL_97091d736ccd41879c3e0d4ebb035764"
          }
        },
        "14cde806cf2c4a22b8b21b409cf7482c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6365c9eef1af46a9a051b509be6059ed",
            "placeholder": "",
            "style": "IPY_MODEL_0bf42c884453444ebc5e6d38f94ec3c1",
            "value": "SanityCheckingDataLoader0:0%"
          }
        },
        "3261efeb2e644db9b7ce94ff7a6717c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9adeac374d914d678332ffc714d6db49",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39789921577a4247803357c094dc6b40",
            "value": 0
          }
        },
        "f8a4cef5dcbc487b92d4ec13db4ab668": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be75b53f12654086a52f34e99d40224b",
            "placeholder": "",
            "style": "IPY_MODEL_fe84b402965540d0936ab3d9842de636",
            "value": "0/2[00:00&lt;?,?it/s]"
          }
        },
        "97091d736ccd41879c3e0d4ebb035764": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "6365c9eef1af46a9a051b509be6059ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bf42c884453444ebc5e6d38f94ec3c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9adeac374d914d678332ffc714d6db49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39789921577a4247803357c094dc6b40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be75b53f12654086a52f34e99d40224b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe84b402965540d0936ab3d9842de636": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}